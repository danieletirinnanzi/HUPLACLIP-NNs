exp_name: MLP_CNN_VGG_experiment_configuration
graph_size: 100
# type of correction to use (in graphs_generation.py):
# - p_increase (old correction): increasing the p value of the graph without the clique so that the average degree is matched between the two graphs
# - p_reduce (new correction): reducing the p value of the graph where the clique will be added
p_correction_type: p_reduce

models:

  # each instance of "models" will be trained and tested with the specified hyperparameters
  
  - model_name: MLP
    hyperparameters:
      
      # ARCHITECTURE:
      l1: 1000
      l2: 500
      l3: 100
      l3: 100
      dropout_prob: 0.2
      learning_rate: 0.01      

      # TRAINING HYPERPARAMETERS:
      # training cycles (TO BE INCREASED):
      num_cycles: 10
      num_training_steps: 40
      # training and validation set sizes (TO BE INCREASED):
      num_train: 16
      num_val: 16
      # other hyperparameters:
      learning_rate: 0.01
      dropout: 0.2
      # training structure:
      max_clique_size_proportion: 0.6 # during training, clique will be at most 60% of the graph size
      min_clique_size_proportion: 0.4 # during training, clique will be at most 40% of the graph size
      jump: 5
      save_step: 10
      # optimizer and loss function:
      optimizer: Adam
      loss_function: BCELoss

      # TESTING HYPERPARAMETERS:
      max_clique_size_proportion_test: 0.7 # during testing, clique will be at most 70% of the graph size
      num_test: 16  # (TO BE INCREASED) number of graphs in each test iteration
      jump_test: 1  # increase in clique size between test iterations
      test_iterations: 15 # number of times for which a single clique size is tested


  - model_name: CNN
    hyperparameters:
      
      # ARCHITECTURE:
      # number of hidden layers and number of neurons in each hidden layer:
      c1: 5
      c2: 10
      c3: 15
      c4: 20  #MIGHT BE UNUSED?
      l3: 100
      dropout_prob: 0.2
      kernel_size: 3
      learning_rate: 0.01
      
      # TRAINING HYPERPARAMETERS:
      # training cycles (TO BE INCREASED):
      num_cycles: 10
      num_training_steps: 40
      # training and validation set sizes (TO BE INCREASED):
      num_train: 16
      num_val: 16
      # training structure:
      max_clique_size_proportion: 0.6 # during training, clique will be at most 60% of the graph size
      min_clique_size_proportion: 0.4 # during training, clique will be at most 40% of the graph size
      jump: 5
      save_step: 10
      # optimizer and loss function:
      optimizer: Adam
      loss_function: BCELoss

      # TESTING HYPERPARAMETERS:
      max_clique_size_proportion_test: 0.7 # during testing, clique will be at most 70% of the graph size
      num_test: 16  # (TO BE INCREASED) number of graphs in each test iteration
      jump_test: 1  # increase in clique size between test iterations
      test_iterations: 15 # number of times for which a single clique size is tested      

  - model_name: VGG16
    hyperparameters:
      
      # TRAINING HYPERPARAMETERS:
      # training cycles (TO BE INCREASED):
      num_cycles: 10
      num_training_steps: 40
      # training and validation set sizes (TO BE INCREASED):
      num_train: 16
      num_val: 16
      # training structure:
      max_clique_size_proportion: 0.6 # during training, clique will be at most 60% of the graph size
      min_clique_size_proportion: 0.4 # during training, clique will be at most 40% of the graph size
      jump: 5
      save_step: 10
      # optimizer and loss function:
      optimizer: Adam
      loss_function: BCELoss

      # TESTING HYPERPARAMETERS:
      max_clique_size_proportion_test: 0.7 # during testing, clique will be at most 70% of the graph size
      num_test: 16  # (TO BE INCREASED) number of graphs in each test iteration
      jump_test: 1  # increase in clique size between test iterations
      test_iterations: 15 # number of times for which a single clique size is tested      