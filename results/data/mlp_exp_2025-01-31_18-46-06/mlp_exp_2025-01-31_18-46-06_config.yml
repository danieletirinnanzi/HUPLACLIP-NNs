elapsed_time: '0:36:50.727957'
exp_name: mlp_exp
graph_size_values:
- 400
models:
- architecture:
    dropout_prob: 0.2
    layers:
    - 200
    - 190
    - 180
    - 170
    - 160
    - 150
    - 140
    - 130
    - 120
    - 110
    - 100
    - 90
    - 80
    - 70
    - 60
    - 50
    - 40
    - 30
    - 20
    - 12
  model_name: MLP_20layers
p_correction_type: p_reduce
testing_parameters:
  clique_testing_levels: 100
  max_clique_size_proportion_test: 0.7
  num_test: 32
  test_iterations: 16
training_parameters:
  clique_training_levels: 10
  learning_rate: 0.0001
  loss_function: BCELoss
  max_clique_size_proportion: 0.5
  min_delta: 0.01
  num_train: 32
  num_training_steps: 1000
  num_val: 32
  optimizer: AdamW
  patience: 50
  save_step: 10
  val_exit_loss: 0.1
