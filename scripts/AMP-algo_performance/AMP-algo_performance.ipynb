{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e57308a",
   "metadata": {},
   "source": [
    "Test of AMP algorithm performance, adapted from Rudy's implementation in:\n",
    "https://colab.research.google.com/drive/1gntrdgJ1nfmGJLschTw__um2Bc4v77Ju?usp=sharing#scrollTo=awrUcRDGmSZL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1c8840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import csv\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from scipy import integrate\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15829812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\Desktop\\Virtual Envs\\ML\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# custom imports\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../..\")))\n",
    "\n",
    "from src.utils import load_config\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0456939",
   "metadata": {},
   "source": [
    "# Graphs generation functions (adapted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1ddfe5",
   "metadata": {},
   "source": [
    "Functions adapted from original ones because AMP algo expects a different input adjacency matrix (-1 and 1 for single tiles;\n",
    "0 on the diagonal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77f756c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plant_clique(graph, clique_size, graph_size):\n",
    "    \"\"\"\n",
    "    Plants a clique of specified size within a given graph.\n",
    "\n",
    "    Args:\n",
    "        graph (torch.Tensor): Adjacency matrix representing the graph.\n",
    "        size (int): Size of the clique to be planted.\n",
    "        graph_size (int): Total number of nodes in the graph.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Modified adjacency matrix with the planted clique.\n",
    "    \"\"\"\n",
    "    # adding the planted clique to the adjacency matrix in the top left corner\n",
    "    graph[:clique_size, :clique_size] = torch.ones(clique_size, clique_size)\n",
    "    # creating a random permutation of the nodes\n",
    "    random_permutation = torch.randperm(graph_size)\n",
    "    # placing the rows and columns of the adjacency matrix according to the random permutation\n",
    "    graph = graph[random_permutation[:, None], random_permutation]\n",
    "    return graph\n",
    "\n",
    "\n",
    "def generate_graph(\n",
    "    on_off_label: int,\n",
    "    graph_size: int,\n",
    "    clique_size: int,\n",
    "    p_correction_type: str,\n",
    "    input_magnification: bool,\n",
    "    p_nodes: float = 0.5,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generates a graph with or without a planted clique with the specified correction.\n",
    "\n",
    "    Args:\n",
    "        on_off_label (int): Label indicating whether the graph will have a planted clique.\n",
    "        graph_size (int): Number of nodes in the graph.\n",
    "        clique_size (int): Size of the planted clique.\n",
    "        p_correction_type (str): Type of p correction to apply.\n",
    "        input_magnification (bool): Whether the input needs to be magnified. If True, the graph will be made a 2400x2400 tensor.\n",
    "        p_nodes (float): Probability of an edge being present between two nodes.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If an invalid p_correction_type is provided.\n",
    "        ValueError: If the clique size is too large for the graph size and the \"p_reduce\" correction type is used.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Adjacency matrix representing a graph with the specified features.\n",
    "    \"\"\"\n",
    "\n",
    "    # differentiating between the two types of correction:\n",
    "    if p_correction_type == \"p_increase\":\n",
    "        # (OLD CORRECTION) increasing the p value of the graph without the clique so that the average degree is matched between the two graphs\n",
    "\n",
    "        # generating lower triangle of the adjacency matrix\n",
    "        if on_off_label:\n",
    "            # clique present\n",
    "            adjacency_matrix = torch.bernoulli(\n",
    "                p_nodes * torch.ones(graph_size, graph_size)\n",
    "            )  # regular graph without clique\n",
    "            # adding clique to adjacency matrix\n",
    "            adjacency_matrix = plant_clique(adjacency_matrix, clique_size, graph_size)\n",
    "\n",
    "        else:\n",
    "            # clique not present\n",
    "            p_corrected = p_nodes + (1 - p_nodes) * (\n",
    "                (clique_size * (clique_size - 1)) / (graph_size * (graph_size - 1))\n",
    "            )\n",
    "            adjacency_matrix = torch.bernoulli(\n",
    "                p_corrected * torch.ones(graph_size, graph_size)\n",
    "            )\n",
    "\n",
    "        # generating upper triangular matrix\n",
    "        upper_triangular = torch.triu(adjacency_matrix)\n",
    "        adjacency_matrix = upper_triangular + torch.transpose(upper_triangular, 0, 1)\n",
    "        adjacency_matrix.fill_diagonal_(0)\n",
    "\n",
    "    elif p_correction_type == \"p_reduce\":\n",
    "        # (NEW CORRECTION) reducing the p value of the graph where the clique will be added\n",
    "\n",
    "        # - making sure that the \"p_reduce\" corrected probability of association will be positive for requested clique size\n",
    "        if clique_size > (\n",
    "            (1 + math.sqrt(1 + 4 * p_nodes * graph_size * (graph_size - 1))) / 2\n",
    "        ):\n",
    "            clique_limit = int(\n",
    "                (1 + math.sqrt(1 + 4 * p_nodes * graph_size * (graph_size - 1))) / 2\n",
    "            )\n",
    "            raise ValueError(\n",
    "                f\"Clique size {clique_size} in a graph of size {graph_size} leads to a negative corrected probability of association between nodes. Please choose a clique size smaller than {round(clique_limit)}\"\n",
    "            )\n",
    "\n",
    "        # generating lower triangle of the adjacency matrix\n",
    "        if on_off_label:\n",
    "            # clique present (new correction acts on the reduction of p before adding the clique):\n",
    "            # - computing the new probability of association\n",
    "            p_corrected = (\n",
    "                p_nodes * graph_size * (graph_size - 1)\n",
    "                - clique_size * (clique_size - 1)\n",
    "            ) / ((graph_size - clique_size) * (graph_size + clique_size - 1))\n",
    "            # - creating the new random graph with the probability just computed\n",
    "            adjacency_matrix = torch.bernoulli(\n",
    "                p_corrected * torch.ones(graph_size, graph_size)\n",
    "            )  # regular graph without clique, but with reduced p value\n",
    "            # adding clique to adjacency matrix\n",
    "            adjacency_matrix = plant_clique(adjacency_matrix, clique_size, graph_size)\n",
    "\n",
    "        else:\n",
    "            # clique not present (no need to correct)\n",
    "            adjacency_matrix = torch.bernoulli(\n",
    "                p_nodes * torch.ones(graph_size, graph_size)\n",
    "            )\n",
    "\n",
    "        # generating upper triangular matrix (MODIFIED FOR AMP ALGO COMPATIBILITY)\n",
    "        upper_triangular = torch.triu(adjacency_matrix)\n",
    "        adjacency_matrix = upper_triangular + torch.transpose(upper_triangular, 0, 1)\n",
    "        adjacency_matrix.fill_diagonal_(0)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid p_correction_type. Must be either 'p_increase' or 'p_reduce'\"\n",
    "        )\n",
    "\n",
    "    # transform zeros to -1s, keeping diagonal elements = 0\n",
    "    adjacency_matrix[adjacency_matrix == 0] = -1\n",
    "    adjacency_matrix.fill_diagonal_(0)\n",
    "\n",
    "    return adjacency_matrix\n",
    "\n",
    "\n",
    "def generate_batch_clique_sizes(allowed_clique_sizes, batch_size):\n",
    "    \"\"\"\n",
    "    Generate the clique sizes for each graph in the batch (based on the allowed clique size values).\n",
    "\n",
    "    Parameters:\n",
    "    allowed_clique_sizes (np.ndarray): Allowed clique size values.\n",
    "    batch_size (int): Size of the batch to generate.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Array of generated clique sizes for each graph in the batch.\n",
    "    \"\"\"\n",
    "    # TESTING INPUT VALUES:\n",
    "    if not isinstance(allowed_clique_sizes, np.ndarray):\n",
    "        raise ValueError(\"allowed_clique_sizes must be a numpy array\")\n",
    "    if not isinstance(batch_size, int):\n",
    "        raise ValueError(\"batch_size must be an integer\")\n",
    "    # if more than one clique size value is allowed, checking that last value of array is the smallest one:\n",
    "    if len(allowed_clique_sizes) > 1:\n",
    "        if min(allowed_clique_sizes) != allowed_clique_sizes[-1]:\n",
    "            raise ValueError(\n",
    "                \"the last provided clique size value is not the smallest one: something might be wrong with the curriculum training procedure\"\n",
    "            )\n",
    "    # END TESTING INPUT VALUES\n",
    "\n",
    "    # probability of single clique size value is < 0.25:\n",
    "    if 1 / len(allowed_clique_sizes) < 0.25:\n",
    "        # - set minimum probability value for lowest clique size\n",
    "        prob_lowest = 0.25\n",
    "        # - calculate probability for remaining values (easier versions):\n",
    "        prob_easier = (1 - 0.25) / (len(allowed_clique_sizes) - 1)\n",
    "        # - define array of probabilities:\n",
    "        allowed_clique_sizes_probs = np.full(len(allowed_clique_sizes) - 1, prob_easier)\n",
    "        allowed_clique_sizes_probs = np.concatenate(\n",
    "            (allowed_clique_sizes_probs, [prob_lowest])\n",
    "        )\n",
    "\n",
    "    # probability of single clique size value is >= 0.25\n",
    "    else:\n",
    "        # - simply define single prob value\n",
    "        prob_each = 1 / len(allowed_clique_sizes)\n",
    "        allowed_clique_sizes_probs = np.full(len(allowed_clique_sizes), prob_each)\n",
    "\n",
    "    # Normalize the probabilities to ensure they sum to 1 (in case of rounding errors)\n",
    "    allowed_clique_sizes_probs /= np.sum(allowed_clique_sizes_probs)\n",
    "\n",
    "    # Generate the clique size array\n",
    "    batch_clique_sizes = np.random.choice(\n",
    "        allowed_clique_sizes, batch_size, p=allowed_clique_sizes_probs\n",
    "    )\n",
    "\n",
    "    return batch_clique_sizes\n",
    "\n",
    "\n",
    "def generate_batch(\n",
    "    number_of_graphs: int,\n",
    "    graph_size: int,\n",
    "    clique_size_array: List[int],\n",
    "    p_correction_type: str,\n",
    "    input_magnification: bool,\n",
    "    p_clique: float = 0.5,\n",
    "    p_nodes: float = 0.5,\n",
    ") -> Tuple:\n",
    "    \"\"\"\n",
    "    Generates batch of graphs. The size of each graph in the batch can be different, as well as the clique size.\n",
    "\n",
    "    Args:\n",
    "        number_of_graphs (int): Number of graphs in the batch.\n",
    "        graph_size (int): Number of nodes in the graphs of the batch.\n",
    "        clique_size_array (List[int]): Size of the planted clique in each graph of the batch.\n",
    "        p_correction_type (str): Type of p correction to apply.\n",
    "        input_magnification (bool): Whether the input needs to be magnified. If True, the graph will be made a 2400x2400 tensor.\n",
    "        p_clique (float): Probability of a graph having a planted clique. Default is 0.5.\n",
    "        p_nodes (float): Probability of an edge being present between two nodes. Default is 0.5.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the batch of graphs and the corresponding on_off flags.\n",
    "    \"\"\"\n",
    "\n",
    "    # Testing validity of input parameters:\n",
    "    if number_of_graphs == 0:\n",
    "        raise ValueError(\"At least one graph must be generated.\")\n",
    "    # - testing that number of graphs and clique size array length match:\n",
    "    if len(clique_size_array) != number_of_graphs:\n",
    "        raise ValueError(\n",
    "            \"The number of graphs must be the same of clique size array length\"\n",
    "        )\n",
    "    # - testing that all values are positive integers:\n",
    "    if (\n",
    "        not all(\n",
    "            isinstance(size, (int, np.int32, np.int64)) for size in clique_size_array\n",
    "        )\n",
    "        or any(size <= 0 for size in clique_size_array)\n",
    "        or graph_size <= 0\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"All clique size values and graph size value must be positive integers\"\n",
    "        )\n",
    "    # - testing that the probability values are in the [0-1] range:\n",
    "    elif (p_nodes <= 0 or p_nodes > 1) or (p_clique <= 0 or p_clique > 1):\n",
    "        raise ValueError(\n",
    "            \"Probability of association between nodes and probability of the presence of a clique must be included in the range [0-1]\"\n",
    "        )\n",
    "\n",
    "    # Generating the labels (with/without clique)\n",
    "    on_off = torch.bernoulli(p_clique * torch.ones(number_of_graphs))\n",
    "    # Generating the graph_list that will contain the adjacency matrices (now filled with zeros, will be filled with the actual adjacency matrices later on)\n",
    "    # - magnified input (for all models except MLP):\n",
    "    if input_magnification:\n",
    "        graphs = torch.zeros(number_of_graphs, 1, 2400, 2400)\n",
    "    # - standard input (for MLP):\n",
    "    else:\n",
    "        graphs = torch.zeros(number_of_graphs, 1, graph_size, graph_size)\n",
    "\n",
    "    for i in range(number_of_graphs):\n",
    "        graphs[i, 0] = generate_graph(\n",
    "            on_off[i],\n",
    "            graph_size,\n",
    "            clique_size_array[i],\n",
    "            p_correction_type,\n",
    "            input_magnification,\n",
    "            p_nodes,\n",
    "        )\n",
    "\n",
    "    # returning the generated graphs and the on_off flag\n",
    "    return graphs, on_off.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf68776",
   "metadata": {},
   "source": [
    "# AMP algo definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c0830a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- params ----------\n",
    "save_mu = {}\n",
    "save_L = {}\n",
    "d = 5  # maximum exponent degree\n",
    "\n",
    "# ---------- precompute mu and L up to level T ----------\n",
    "def compute_mu_L(T):\n",
    "    # returns lists indexed by level (0..T). We will keep index 0 unused for mu (mu[1]=1)\n",
    "    fact = [math.factorial(k) for k in range(d+1)]\n",
    "    mu_vals = [None] * (T + 1)\n",
    "    L_vals = [None] * (T + 1)\n",
    "    mu_vals[1] = 1.0\n",
    "    # L(1) depends on mu(1)\n",
    "    def L_integrand_factory(mu_l):\n",
    "        def integrand(x):\n",
    "            poly = 0.0\n",
    "            xval = x\n",
    "            for k in range(d+1):\n",
    "                poly += (mu_l**k) * (xval**k) / fact[k]\n",
    "            return norm.pdf(x) * (poly**2)\n",
    "        return integrand\n",
    "    L_vals[1] = math.sqrt(integrate.quad(L_integrand_factory(mu_vals[1]), -15, 15)[0])\n",
    "    # now iteratively compute mu_l and L_l\n",
    "    for l in range(2, T+1):\n",
    "        # integrand for mu_l uses p(., l-1) with mu_{l-1}, L_{l-1}\n",
    "        mu_prev = mu_vals[l-1]\n",
    "        L_prev = L_vals[l-1]\n",
    "        def mu_integrand(x):\n",
    "            z = mu_prev + x\n",
    "            poly = 0.0\n",
    "            zpow = 1.0\n",
    "            for k in range(d+1):\n",
    "                poly += (mu_prev**k) * (zpow) / fact[k]\n",
    "                zpow *= z\n",
    "            return norm.pdf(x) * (poly / L_prev)\n",
    "        mu_l = integrate.quad(mu_integrand, -15, 15)[0]\n",
    "        mu_vals[l] = mu_l\n",
    "        # now L_l\n",
    "        L_vals[l] = math.sqrt(integrate.quad(L_integrand_factory(mu_l), -15, 15)[0])\n",
    "    # precompute coefficient tensors coeffs[l] = [mu_l**k / k!] for k=0..d\n",
    "    coeffs = []\n",
    "    for l in range(T+1):\n",
    "        if l == 0:\n",
    "            coeffs.append(None)\n",
    "        else:\n",
    "            coeffs.append(torch.tensor([ (mu_vals[l]**k) / math.factorial(k) for k in range(d+1) ], dtype=torch.get_default_dtype()))\n",
    "    return mu_vals, L_vals, coeffs\n",
    "\n",
    "# ---------- vectorized polynomial for torch tensors ----------\n",
    "def p_torch(z, l, coeffs, L_vals):\n",
    "    # z: torch tensor (any shape)\n",
    "    if l == 0:\n",
    "        return torch.ones_like(z)\n",
    "    coeff = coeffs[l]                 # tensor shape (d+1,)\n",
    "    res = torch.zeros_like(z)\n",
    "    z_pow = torch.ones_like(z)        # z**0\n",
    "    for k in range(coeff.shape[0]):\n",
    "        res = res + coeff[k] * z_pow\n",
    "        z_pow = z_pow * z\n",
    "    return res / float(L_vals[l])\n",
    "\n",
    "# ---------- message passing ----------\n",
    "def CliqueMarginals(W, t, coeffs, L_vals):\n",
    "    # W: torch [n,n], symmetric\n",
    "    n = W.shape[0]\n",
    "    A = W / math.sqrt(n)\n",
    "    A = A.clone()\n",
    "    A.fill_diagonal_(0.0)\n",
    "\n",
    "    theta_ij = torch.ones((n, n), dtype=W.dtype, device=W.device)\n",
    "    theta_ij.fill_diagonal_(0.0)\n",
    "\n",
    "    for it in range(t):\n",
    "        p_vals = p_torch(theta_ij, it, coeffs, L_vals)    # shape (n,n)\n",
    "        theta_i = torch.sum(A * p_vals, dim=1)            # shape (n,)\n",
    "        theta_ij = theta_i.unsqueeze(1) - A * p_vals.T    # use p_vals.T instead of recomputing\n",
    "        theta_ij.fill_diagonal_(0.0)\n",
    "    return theta_i\n",
    "\n",
    "# ---------- decision procedure ----------\n",
    "def CliqueDecision(W, n, k, t=2, eps=0.0, method='eig_threshold', mu_t=None, device='cpu'):\n",
    "    if not isinstance(W, torch.Tensor):\n",
    "        W = torch.tensor(W, dtype=torch.get_default_dtype(), device=device)\n",
    "    else:\n",
    "        W = W.to(device)\n",
    "\n",
    "    mu_vals, L_vals, coeffs = compute_mu_L(t)\n",
    "    x = CliqueMarginals(W, t, coeffs, L_vals)  # torch tensor\n",
    "\n",
    "    mu_t_val = float(mu_vals[t]) if mu_t is None else float(mu_t)\n",
    "    candidates_mask = (x > mu_t_val)\n",
    "    index = torch.nonzero(candidates_mask, as_tuple=False).view(-1)\n",
    "\n",
    "    if index.numel() == 0:\n",
    "        return 0\n",
    "\n",
    "    m = int(index.numel())\n",
    "    W_sub = W.index_select(0, index).index_select(1, index) / math.sqrt(max(1, m))\n",
    "    eigvals, eigvecs = torch.linalg.eigh(W_sub)\n",
    "    lambda_max = float(eigvals[-1].cpu().item())\n",
    "\n",
    "    if method == 'eig_threshold':\n",
    "        return int(lambda_max > 2.0 + eps)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03238aa",
   "metadata": {},
   "source": [
    "# Test function (adapted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a72de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration file loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# TEST FUNCTION\n",
    "# read configuration file:\n",
    "config = load_config(\n",
    "    os.path.join(\"AMP-algo_test_config.yml\")\n",
    ")  # CHANGE THIS TO PERFORM DIFFERENT EXPERIMENTS\n",
    "\n",
    "# looping over the different graph sizes in the experiment:\n",
    "for graph_size in config[\"graph_size_values\"]:\n",
    "\n",
    "    # Create empty dictionaries for storing testing results:\n",
    "    fraction_correct_results = {}  # Fraction correct for each clique size\n",
    "    metrics_results = {}  # Metrics dictionary\n",
    "\n",
    "    # Calculate max clique size for testing (proportion of graph size):\n",
    "    if graph_size in [100, 150, 200]:\n",
    "        max_clique_size_proportion_test = config[\"testing_parameters\"][\"max_clique_size_proportion_test\"][0]\n",
    "    elif graph_size in [300, 400, 480, 600]:\n",
    "        max_clique_size_proportion_test = config[\"testing_parameters\"][\"max_clique_size_proportion_test\"][1]\n",
    "    elif graph_size in [800, 1000, 1200]:\n",
    "        max_clique_size_proportion_test = config[\"testing_parameters\"][\"max_clique_size_proportion_test\"][2]                        \n",
    "    elif graph_size in [1500, 2000]:\n",
    "        max_clique_size_proportion_test = config[\"testing_parameters\"][\"max_clique_size_proportion_test\"][3]                            \n",
    "    elif graph_size in [3000, 5000]:\n",
    "        max_clique_size_proportion_test = config[\"testing_parameters\"][\"max_clique_size_proportion_test\"][4]\n",
    "    else:\n",
    "        max_clique_size_proportion_test = config[\"testing_parameters\"][\"max_clique_size_proportion_test\"][5]\n",
    "    max_clique_size = int(\n",
    "        max_clique_size_proportion_test * graph_size\n",
    "    )\n",
    "\n",
    "    # Calculate array of clique sizes for all test curriculum\n",
    "    # NOTE: if max clique size is smaller than the the number of test levels, use max clique size as the number of test levels\n",
    "    clique_sizes = np.linspace(\n",
    "        max_clique_size,\n",
    "        1,\n",
    "        num=min(max_clique_size, config[\"testing_parameters\"][\"clique_testing_levels\"]),\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Metrics initialization (local to each GPU)\n",
    "    TP, FP, TN, FN = 0, 0, 0, 0  \n",
    "\n",
    "    # Loop for decreasing clique sizes\n",
    "    for current_clique_size in clique_sizes:\n",
    "\n",
    "        # Initialize fraction correct list, updated at each test iteration\n",
    "        fraction_correct_list = []\n",
    "\n",
    "        # Loop for testing iterations:\n",
    "        for test_iter in range(config[\"testing_parameters\"][\"test_iterations\"]):\n",
    "\n",
    "            # Generate clique size value of each graph in the current batch\n",
    "            clique_size_array_test = generate_batch_clique_sizes(\n",
    "                np.array([current_clique_size]),\n",
    "                config[\"testing_parameters\"][\"num_test\"],\n",
    "            )\n",
    "\n",
    "            # Generate validation graphs\n",
    "            test = generate_batch(\n",
    "                config[\"testing_parameters\"][\"num_test\"],\n",
    "                graph_size,\n",
    "                clique_size_array_test,\n",
    "                config[\"p_correction_type\"],\n",
    "                False,\n",
    "            )\n",
    "            \n",
    "            hard_output = torch.zeros([config[\"testing_parameters\"][\"num_test\"]])\n",
    "            \n",
    "            for graph_index, graph in enumerate(test[0]):\n",
    "                AMP_output = CliqueDecision(\n",
    "                    graph.squeeze(), graph_size, current_clique_size\n",
    "                )\n",
    "                hard_output[graph_index] = AMP_output\n",
    "            \n",
    "            # transforming hard_output and test_labels to torch tensors:\n",
    "            hard_output = torch.tensor(hard_output, dtype=torch.float32)\n",
    "            test_labels = torch.tensor(test[1], dtype=torch.float32)\n",
    "            \n",
    "            # Compute metrics\n",
    "            TP += ((hard_output == 1) & (test_labels == 1)).sum().item()\n",
    "            FP += ((hard_output == 1) & (test_labels == 0)).sum().item()\n",
    "            TN += ((hard_output == 0) & (test_labels == 0)).sum().item()\n",
    "            FN += ((hard_output == 0) & (test_labels == 1)).sum().item()\n",
    "\n",
    "            # updating fraction correct list with the accuracy of the current test iteration:\n",
    "            fraction_correct_list.append(\n",
    "                (hard_output == test_labels).sum().item()\n",
    "                / (1.0 * config[\"testing_parameters\"][\"num_test\"])\n",
    "            )\n",
    "            \n",
    "            # delete unused variables\n",
    "            del test, hard_output, test_labels, clique_size_array_test        \n",
    "\n",
    "        # Updating dictionary after all test iterations for current clique size have been completed:\n",
    "        fraction_correct_results[current_clique_size] = round(\n",
    "            sum(fraction_correct_list) / len(fraction_correct_list), 2\n",
    "        )\n",
    "\n",
    "        # Printing the size of the clique just tested and the corresponding test accuracy:\n",
    "        print(\n",
    "            f\"||| Completed testing for clique = {current_clique_size}. \"\n",
    "            f\"Average fraction correct = {fraction_correct_results[current_clique_size]}\"\n",
    "        )\n",
    "        print(\"|||===========================================================\")\n",
    "\n",
    "    # - notify completion of testing:\n",
    "    print(f\"| Finished testing AMP algo at N = {graph_size}.\")\n",
    "\n",
    "    # Computing metrics:\n",
    "    precision = TP / (TP + FP + 1e-10)\n",
    "    recall = TP / (TP + FN + 1e-10)\n",
    "    F1 = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "    # AUC - ROC cannot be calculated (no soft outputs)\n",
    "    # num_params has no meaning\n",
    "    metrics_results = {\n",
    "        \"TP\": TP,\n",
    "        \"FP\": FP,\n",
    "        \"TN\": TN,\n",
    "        \"FN\": FN,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"F1\": F1,\n",
    "        \"AUC_ROC\": np.nan,\n",
    "        \"total_params\": np.nan,\n",
    "    }\n",
    "\n",
    "    # Saving accuracy results in .csv file:\n",
    "    # - defining file name and path:\n",
    "    file_path = os.path.join(\n",
    "        os.getcwd(), \"results\", f\"AMP-algo_N{graph_size}_fraction_correct.csv\"\n",
    "    )\n",
    "    # - saving the dictionary as a .csv file:\n",
    "    with open(file_path, \"w\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"clique size\", \"fraction correct\"])  # Add column labels\n",
    "        for key, value in fraction_correct_results.items():\n",
    "            writer.writerow([key, value])\n",
    "    # Saving metrics results in .csv file:\n",
    "    # - defining file name and path:\n",
    "    file_path = os.path.join(\n",
    "        os.getcwd(), \"results\", f\"AMP-algo_N{graph_size}_metrics.csv\"\n",
    "    )\n",
    "    # - saving the dictionary as a .csv file:\n",
    "    pd.DataFrame([metrics_results]).to_csv(file_path, index=False)\n",
    "\n",
    "    print(f\"- AMP Results saved successfully for N = {graph_size}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
