{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1c8840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import csv\n",
    "from scipy.stats import binom\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15829812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\Desktop\\Virtual Envs\\ML\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# custom imports\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../..\")))\n",
    "\n",
    "from src.utils import load_config\n",
    "import src.graphs_generation as graphs_gen\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e9780c",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2f8bb6",
   "metadata": {},
   "source": [
    "## Common functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80207adc",
   "metadata": {},
   "source": [
    "Functions adapted from:\n",
    "`\\HUPLACLIP-NNs\\scripts\\visualizations\\degree_distribution.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a6b2742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_correction(p_nodes, graph_size, clique_size):\n",
    "    '''Returns the value of the corrected p-value in the graph with clique (\"p_reduce\" case) '''\n",
    "    p_corrected = (\n",
    "        p_nodes * graph_size * (graph_size - 1)\n",
    "        - clique_size * (clique_size - 1)\n",
    "    ) / ((graph_size - clique_size) * (graph_size + clique_size - 1))\n",
    "    return p_corrected\n",
    "\n",
    "# P(d|C=0)\n",
    "def p_noclique(degree_arr, graph_size):\n",
    "    ''' \n",
    "    For an array of degree values (degree_arr: ndarray of shape [N_graphs, 1, graph_size]), returns the probability that (in a graph WITHOUT the clique) a node has exactly that degree.    \n",
    "    Returns: ndarray of probabilities, same shape as degree_arr\n",
    "    '''\n",
    "    return binom.pmf(degree_arr, \n",
    "                     graph_size-1, \n",
    "                     0.5    # \"p_reduce\" correction only acts on graph with clique\n",
    "                     )\n",
    "\n",
    "def expected_count_noclique(degree_arr, graph_size):\n",
    "    '''\n",
    "    Uses p_noclique to obtain the number of nodes that (in a graph WITHOUT the clique) are expected to have exactly that degree.\n",
    "    '''\n",
    "    # expected count = graph_size * probability_per_node\n",
    "    return graph_size * p_noclique(degree_arr, graph_size)\n",
    "\n",
    "# P(d|C=1)\n",
    "def p_ingroup(degree_arr, graph_size, clique_size, p_corrected):\n",
    "    ''' \n",
    "    For an array of degree values (degree_arr: ndarray of shape [N_graphs, 1, graph_size]), returns the probability that (in a graph WITH the clique) a node INSIDE the clique has exactly that degree.    \n",
    "    Returns: ndarray of probabilities, same shape as degree_arr\n",
    "    '''\n",
    "    return binom.pmf(degree_arr - (clique_size-1),  # number of non-clique connections\n",
    "                     graph_size - clique_size,      # number of possible non-clique nodes\n",
    "                     p_corrected\n",
    "                     )\n",
    "\n",
    "def p_outgroup(degree_arr, graph_size, clique_size, p_corrected):\n",
    "    ''' \n",
    "    For an array of degree values (degree_arr: ndarray of shape [N_graphs, 1, graph_size]), returns the probability that (in a graph WITH the clique) a node OUTSIDE the clique has exactly that degree.    \n",
    "    Returns: ndarray of probabilities, same shape as degree_arr\n",
    "    '''\n",
    "    return binom.pmf(degree_arr, \n",
    "                     graph_size-1, \n",
    "                     p_corrected\n",
    "                     )\n",
    "\n",
    "def expected_count_clique(degree_arr, graph_size, clique_size, p_corrected):\n",
    "    '''Combines p_outgroup and p_ingroup (single mixture) to obtain the number of nodes that (in a graph WITH the clique) are expected to have exactly that degree'''\n",
    "    prob = clique_size/graph_size * p_ingroup(degree_arr, graph_size, clique_size, p_corrected) + (1-clique_size/graph_size) * p_outgroup(degree_arr, graph_size, clique_size, p_corrected)    \n",
    "    # expected count = graph_size * probability_per_node\n",
    "    prob = graph_size * prob\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515941ec",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa1dd48",
   "metadata": {},
   "source": [
    "\"Ideal MLP\" designed starting from this initial sketch (11/11/2025):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7bd5cb",
   "metadata": {},
   "source": [
    "![Alt text](../../scripts/Ideal-MLP_performance/whiteboard_images/Ideal-MLP-sketch.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f8e294",
   "metadata": {},
   "source": [
    "More complete diagram (17/11/2025):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d16ddf",
   "metadata": {},
   "source": [
    "![Alt text](../../scripts/Ideal-MLP_performance/whiteboard_images/Zoom-Meeting_2025-11-17_Ideal-MLP_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c13085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tau values:  tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100])\n",
      "Clique size values:  tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
      "        37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
      "        55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70])\n",
      "(101,)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100., dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100., dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100., dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100., dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100., dtype=torch.float64)\n",
      "tensor(100., dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n",
      "tensor(100.0000, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "class Ideal_MLP(nn.Module):\n",
    "    def __init__(self, graph_size:int, max_clique_prop:float = 0.7):\n",
    "        super().__init__()\n",
    "        self.N = graph_size\n",
    "        # Precomputed variables:\n",
    "        # - array of bin edges: \n",
    "        self.tau = torch.arange(0, self.N+1) #NOTE: possible improvement is extending this to actual bins spanning more than 1 single value\n",
    "        print(\"Tau values: \", self.tau)\n",
    "        # - array of clique size values:\n",
    "        max_K = int(max_clique_prop * self.N)\n",
    "        self.clique_size_values = torch.arange(1, max_K + 1)\n",
    "        print(\"Clique size values: \", self.clique_size_values)\n",
    "        # - expected histograms:\n",
    "        self.expected_hist_no_clique = expected_count_noclique(self.tau, self.N) # dimension: len(self.tau) x 1        \n",
    "        expected_hist_clique = []  # to be filled: list of tensors\n",
    "        for K in self.clique_size_values:\n",
    "            p_corrected = p_correction(0.5, self.N, K)\n",
    "            expected_hist_K = expected_count_clique(self.tau, self.N, K, p_corrected)  # dimension: len(self.tau) x 1 (NOTE: these should sum to N)\n",
    "            expected_hist_clique.append(expected_hist_K)\n",
    "        self.expected_hist_clique = torch.stack(expected_hist_clique, dim=1)  # final dimension: len(self.tau) x clique_size\n",
    "        \n",
    "ideal_MLP = Ideal_MLP(100)        \n",
    "\n",
    "# Processing blocks:\n",
    "# - compute degree of each node (sum over rows/columns of AM)\n",
    "# - compute for all k, for all tau:\n",
    "#   - left/right blocks\n",
    "#   - right - left\n",
    "#   - store in matrix (containing 1 if k_i = tau_j), dim N x k\n",
    "# - sum matrix over k -> how many nodes have degree = tau_j (raw count histogram)\n",
    "# - for each tau_j:\n",
    "#   - diff_clique_tau_j = abs(Raw count histogram - exp.histogram with clique(for all possible clique sizes))\n",
    "# - diff_clique_tau_j -> compute mean\n",
    "# - diff_noclique_tau_j = abs(Raw count histogram - exp.histogram without clique)\n",
    "\n",
    "# OUT: soft output (softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03238aa",
   "metadata": {},
   "source": [
    "# Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a72de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read configuration file:\n",
    "config = load_config(\n",
    "    os.path.join(\"Ideal-MLP_test_config.yml\")\n",
    ")  # CHANGE THIS TO PERFORM DIFFERENT EXPERIMENTS\n",
    "\n",
    "# looping over the different graph sizes in the experiment:\n",
    "for graph_size in config[\"graph_size_values\"]:\n",
    "\n",
    "    # Create empty dictionaries for storing testing results:\n",
    "    fraction_correct_results = {}  # Fraction correct for each clique size\n",
    "    metrics_results_list = []\n",
    "\n",
    "    # Calculate max clique size for testing (proportion of graph size):\n",
    "    if graph_size in [100, 150, 200]:\n",
    "        max_clique_size_proportion_test = config[\"testing_parameters\"][\"max_clique_size_proportion_test\"][0]\n",
    "    elif graph_size in [300, 400, 480, 600]:\n",
    "        max_clique_size_proportion_test = config[\"testing_parameters\"][\"max_clique_size_proportion_test\"][1]\n",
    "    elif graph_size in [800, 1000, 1200]:\n",
    "        max_clique_size_proportion_test = config[\"testing_parameters\"][\"max_clique_size_proportion_test\"][2]                        \n",
    "    elif graph_size in [1500, 2000]:\n",
    "        max_clique_size_proportion_test = config[\"testing_parameters\"][\"max_clique_size_proportion_test\"][3]                            \n",
    "    elif graph_size in [3000, 5000]:\n",
    "        max_clique_size_proportion_test = config[\"testing_parameters\"][\"max_clique_size_proportion_test\"][4]\n",
    "    else:\n",
    "        max_clique_size_proportion_test = config[\"testing_parameters\"][\"max_clique_size_proportion_test\"][5]\n",
    "    max_clique_size = int(\n",
    "        max_clique_size_proportion_test * graph_size\n",
    "    )\n",
    "\n",
    "    # Calculate array of clique sizes for all test curriculum\n",
    "    # NOTE: if max clique size is smaller than the the number of test levels, use max clique size as the number of test levels\n",
    "    clique_sizes = np.linspace(\n",
    "        max_clique_size,\n",
    "        1,\n",
    "        num=min(max_clique_size, config[\"testing_parameters\"][\"clique_testing_levels\"]),\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Metrics initialization\n",
    "    TP, FP, TN, FN = 0, 0, 0, 0  \n",
    "    y_scores = []\n",
    "    y_true = []    \n",
    "\n",
    "    # Loop for decreasing clique sizes\n",
    "    for current_clique_size in clique_sizes:\n",
    "\n",
    "        # Initialize fraction correct list, updated at each test iteration\n",
    "        fraction_correct_list = []\n",
    "\n",
    "        # Loop for testing iterations:\n",
    "        for test_iter in range(config[\"testing_parameters\"][\"test_iterations\"]):\n",
    "\n",
    "            # Generate clique size value of each graph in the current batch\n",
    "            clique_size_array_test = graphs_gen.generate_batch_clique_sizes(\n",
    "                np.array([current_clique_size]),\n",
    "                config[\"testing_parameters\"][\"num_test\"],\n",
    "            )\n",
    "\n",
    "            # Generate validation graphs\n",
    "            test = graphs_gen.generate_batch(\n",
    "                config[\"testing_parameters\"][\"num_test\"],\n",
    "                graph_size,\n",
    "                clique_size_array_test,\n",
    "                config[\"p_correction_type\"],\n",
    "                False,\n",
    "            )\n",
    "            \n",
    "            # Perform prediction on test data\n",
    "            soft_output = ideal_MLP(test[0]).squeeze()\n",
    "            hard_output = (soft_output >= 0.5).int().cpu().numpy()  # converting to hard output (0/1)\n",
    "            # print(hard_output.shape, test_labels.shape)   # DEBUGGING\n",
    "\n",
    "            # Update global metrics for AUC-ROC\n",
    "            y_scores.extend(soft_output.cpu().tolist())\n",
    "            y_true.extend(test[1].cpu().tolist())\n",
    "             \n",
    "            # transforming hard_output and test_labels to torch tensors:\n",
    "            hard_output = torch.tensor(hard_output, dtype=torch.float32)\n",
    "            test_labels = torch.tensor(test[1], dtype=torch.float32)\n",
    "            \n",
    "            # Compute metrics\n",
    "            TP += ((hard_output == 1) & (test_labels == 1)).sum().item()\n",
    "            FP += ((hard_output == 1) & (test_labels == 0)).sum().item()\n",
    "            TN += ((hard_output == 0) & (test_labels == 0)).sum().item()\n",
    "            FN += ((hard_output == 0) & (test_labels == 1)).sum().item()\n",
    "\n",
    "            # updating fraction correct list with the accuracy of the current test iteration:\n",
    "            fraction_correct_list.append(\n",
    "                (hard_output == test_labels).sum().item()\n",
    "                / (1.0 * config[\"testing_parameters\"][\"num_test\"])\n",
    "            )\n",
    "            \n",
    "            # delete unused variables\n",
    "            del test, hard_output, test_labels, clique_size_array_test, soft_output\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # Updating dictionary after all test iterations for current clique size have been completed:\n",
    "        fraction_correct_results[current_clique_size] = round(\n",
    "            sum(fraction_correct_list) / len(fraction_correct_list), 2\n",
    "        )\n",
    "\n",
    "        # Printing the size of the clique just tested and the corresponding test accuracy:\n",
    "        print(\n",
    "            f\"||| Completed testing for clique = {current_clique_size}. \"\n",
    "            f\"Average fraction correct = {fraction_correct_results[current_clique_size]}\"\n",
    "        )\n",
    "        print(\"|||===========================================================\")\n",
    "\n",
    "    # - notify completion of testing:\n",
    "    print(f\"| Finished testing Ideal MLP at N = {graph_size}.\")\n",
    "\n",
    "    # Computing metrics:\n",
    "    precision = TP / (TP + FP + 1e-10)\n",
    "    recall = TP / (TP + FN + 1e-10)\n",
    "    F1 = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "    AUC_ROC = roc_auc_score(y_true, y_scores)\n",
    "    num_params = sum(\n",
    "        p.numel() for p in ideal_MLP.parameters()\n",
    "    )  # storing total number of parameters\n",
    "    metrics_results = {\n",
    "        \"TP\": TP,\n",
    "        \"FP\": FP,\n",
    "        \"TN\": TN,\n",
    "        \"FN\": FN,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"F1\": F1,\n",
    "        \"AUC_ROC\": AUC_ROC,\n",
    "        \"total_params\": num_params,\n",
    "    }\n",
    "\n",
    "    # Saving accuracy results in .csv file:\n",
    "    # - defining file name and path:\n",
    "    file_path = os.path.join(\n",
    "        os.getcwd(), \"results\", f\"Ideal-MLP_N{graph_size}_fraction_correct.csv\"\n",
    "    )\n",
    "    # - saving the dictionary as a .csv file:\n",
    "    with open(file_path, \"w\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"clique size\", \"fraction correct\"])  # Add column labels\n",
    "        for key, value in fraction_correct_results.items():\n",
    "            writer.writerow([key, value])\n",
    "    # Saving metrics results in .csv file:\n",
    "    # - defining file name and path:\n",
    "    file_path = os.path.join(\n",
    "        os.getcwd(), \"results\", f\"Ideal-MLP_N{graph_size}_metrics.csv\"\n",
    "    )\n",
    "    # - saving the dictionary as a .csv file:\n",
    "    pd.DataFrame([metrics_results]).to_csv(file_path, index=False)\n",
    "\n",
    "    print(f\"- Ideal MLP Results saved successfully for N = {graph_size}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
